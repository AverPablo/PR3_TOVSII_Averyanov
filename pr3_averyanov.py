# -*- coding: utf-8 -*-
"""PR3_Averyanov.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jxw61JKbEdp1fm4UEk3oxYGo_IVUmmhF
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import multilabel_confusion_matrix, classification_report

# Загрузка данных
df = pd.read_csv("/content/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv")
# Вывод общей информации
df.head()

# Вывод общей информации
print(df.info())

# Удалим лишние пробелы из названий столбцов и значений
df.columns = df.columns.str.strip()

# Вывод общей информации
print(df.info())

# Проверим пропущенные значения
missing_values = df.isnull().sum()
print("Пропущенные значения:\n", missing_values[missing_values > 0])

# Удалим пропущенные и бесконечные значения
df.replace([np.inf, -np.inf], np.nan, inplace=True)
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

# Удаление столбцов с NaN
df_cleaned_columns = df.dropna(axis=1)

# Проверим пропущенные значения
missing_values = df.isnull().sum()
print("Пропущенные значения:\n", missing_values[missing_values > 0])

print("Уникальные значения метки:", df['Label'].unique())

"""Функция create_attack_labels классифицирует каждый сетевой поток по этапам атаки:

0 - Нормальный трафик (BENIGN)

1 - Разведка (Recon) - определяется по большому количеству пакетов и высокой скорости

2 - Эксплуатация (Exploit) - определяется по большому объему переданных данных

3 - Установка контроля (C&C) - определяется по длительности соединения

4 - Другая подозрительная активность
"""

# Создание multi-label меток для этапов атаки
def create_attack_labels(row):
    labels = []
    if row['Label'] == 'BENIGN':
        labels.append(0)  # Без атаки
    else:
        if row['Total Fwd Packets'] > 1000 and row['Flow Bytes/s'] > 1e6:
            labels.append(1)  # Разведка
        if row['Total Length of Fwd Packets'] > 5000:
            labels.append(2)  # Эксплуатация
        if row['Flow Duration'] > 30000:
            labels.append(3)  # Установка контроля
        if not labels:  # Если ни один этап не подошел
            labels.append(4)  # Другая активность
    return labels

# Применяем функцию и преобразуем в multi-hot encoding
df['Attack Labels'] = df.apply(create_attack_labels, axis=1)
mlb = MultiLabelBinarizer()
y = mlb.fit_transform(df['Attack Labels'])

from sklearn.preprocessing import LabelEncoder, MinMaxScaler


# Подготовка данных для LSTM
features = df.drop(columns=['Flow ID', 'Source IP', 'Destination IP', 'Timestamp', 'Label', 'Attack Labels'])

# Нормализация данных
scaler = MinMaxScaler()
X = scaler.fit_transform(features)

# Группировка по сессиям (Flow ID) и создание последовательностей
grouped = df.groupby('Flow ID')
sequences = []
seq_labels = []

for flow_id, group in grouped:
    if len(group) >= 3:  # Минимум 3 события в сессии
        seq_features = scaler.transform(group[features.columns])
        sequences.append(seq_features)
        # Берем метки первого события в сессии (можно изменить логику)
        seq_labels.append(mlb.transform([group['Attack Labels'].iloc[0]])[0])

# Приведение к единой длине
seq_len = 10
X = pad_sequences(sequences, maxlen=seq_len, dtype='float32', padding='post', truncating='post')
y = np.array(seq_labels)

"""Модель содержит:

Masking слой для обработки переменной длины последовательностей

LSTM слой с 128 нейронами

Полносвязные слои с dropout для регуляризации

Выходной слой с сигмоидальной активацией (для multi-label классификации)
"""

from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking

# Разделение данных
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Построение модели
model = Sequential([
    Masking(mask_value=0.0, input_shape=(seq_len, X.shape[2])),
    LSTM(128, return_sequences=False),
    Dropout(0.4),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(y.shape[1], activation='sigmoid')  # Выходной слой по числу меток
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy', 'Precision', 'Recall'])
model.summary()

   # Обучение multi-label модели
history = model.fit(X_train, y_train,
                   validation_data=(X_test, y_test),
                   epochs=10,
                   batch_size=128)

# После получения y_pred добавим проверку реальных классов
present_classes = np.unique(np.where(y_test == 1)[1])
print("Присутствующие классы в тестовых данных:", present_classes)

# Обновим target_names в соответствии с реальными классами
target_names = ['Normal', 'Recon', 'Exploit', 'C&C', 'Other']
filtered_targets = [target_names[i] for i in present_classes]

# Вывод classification_report с правильными параметрами
print("\nClassification Report:")
print(classification_report(y_test, y_pred,
                          labels=present_classes,
                          target_names=filtered_targets,
                          zero_division=0))

# Confusion matrix
mcm = multilabel_confusion_matrix(y_test[:, present_classes],
                                 y_pred[:, present_classes])

for i, idx in enumerate(present_classes):
    print(f"\n{target_names[idx]} Confusion Matrix:")
    print(mcm[i])
    tn, fp, fn, tp = mcm[i].ravel()
    print(f"True Positives: {tp}, False Positives: {fp}")
    print(f"False Negatives: {fn}, True Negatives: {tn}")

"""Визуализация timeline heatmap
Преобразует временные метки в формат datetime

Группирует атаки по 5-минутным интервалам

Считает количество атак каждого типа в каждом интервале

Строит тепловую карту активности атак по времени
"""

# Timeline Heatmap
df['Timestamp'] = pd.to_datetime(df['Timestamp'])
attack_df = df[df['Label'] == 'DDoS'].copy()
attack_df['Time Window'] = attack_df['Timestamp'].dt.floor('5T')  # 5-минутные окна

# Подсчет активности по этапам в каждом окне
phase_activity = attack_df.groupby('Time Window')['Attack Labels'].apply(
    lambda x: pd.Series({
        'Recon': sum(1 for labels in x if 1 in labels),
        'Exploit': sum(1 for labels in x if 2 in labels),
        'C&C': sum(1 for labels in x if 3 in labels),
        'Other': sum(1 for labels in x if 4 in labels)
    })
).unstack()

# Визуализация heatmap
plt.figure(figsize=(15, 6))
sns.heatmap(phase_activity.T, cmap='YlOrRd', annot=True, fmt='d')
plt.title('DDoS Attack Timeline by Phase')
plt.xlabel('Time Window')
plt.ylabel('Attack Phase')
plt.show()